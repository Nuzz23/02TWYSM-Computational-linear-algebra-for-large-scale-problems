{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>INTRODUCTION</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document represents a small introduction on how to do and what to look for when doing spectral clustering. <br>\n",
    "Starting from either one of this three files: <em>Spiral.csv, Circle.csv</em> or <em>3d_rings.csv</em>.<br>\n",
    "We are going to implement spectral clustering: moreover, we will be building the similarity matrix $W$ the distance matrix $D$ and the Laplacian matrix $L$.<br>\n",
    "Then, we will evaluate eigenvectors and eigenvalues of $L$, compute $U$, and finally clusterize the starting points.\n",
    "<br><br>\n",
    "<b>The authors of the following files are:\n",
    "- Nunzio Licalzi, s344860\n",
    "- Romeo Vercellone, s341967</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>MODULES AND CONSTANTS</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>MODULES AND LIBRARIES</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.linalg import eigh, null_space\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PLOTTING IMPORT\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import display, Math\n",
    "\n",
    "\n",
    "# DISTANCE FUNCTION\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "\n",
    "# CLUSTERING ALGORITHMS\n",
    "from sklearn.cluster import DBSCAN, BisectingKMeans, KMeans, SpectralClustering\n",
    "\n",
    "\n",
    "# METRICS\n",
    "from sklearn.metrics import silhouette_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>CONSTANTS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIRAL_INPUT_FILE = 'Spiral.csv'\n",
    "CIRCLE_INPUT_FILE = 'Circle.csv'\n",
    "RINGS_3D_INPUT_FILE = '3d_rings.csv'\n",
    "EPS = 1e-24\n",
    "NEIGHBORS = 10      # number of neighbors to consider for spectral clustering when building the similarity matrix\n",
    "EIGENPAIRS = 10     # number of eigenpairs to compute\n",
    "USE_SPIRAL = True   # use spiral.csv file or circle.csv file\n",
    "np.random.RandomState(23);      # for reproducibility \n",
    "\n",
    "# ENABLES THE COMPARISON BETWEEN EIGENPAIRS FUNCTION IN THE FILE\n",
    "ENABLE_COMPARISON = True # HEAVILY ADVISED TO KEEP THIS TO FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>0 - READ FUNCTIONS</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>readSpiralInput</b>\n",
    "reads the input file containing the spiral data, \n",
    "<br> accepts as input the path to the csv file containing the data\n",
    "<br> returns a pandas dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSpiralInput(path: str = SPIRAL_INPUT_FILE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the input file containing the spiral data.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The path to the CSV file containing the data. Defaults to SPIRAL_INPUT_FILE.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A pandas DataFrame with columns 'x', 'y', and 'cluster' representing the spiral data.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filepath_or_buffer=path, header=None).set_axis(labels=['x', 'y', 'cluster'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>readCircleInput</b>\n",
    "reads the input file containing the circle data\n",
    "<br> accepts as input the path to the csv file containing the data\n",
    "<br> returns a pandas dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCircleInput(path: str = CIRCLE_INPUT_FILE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the input file containing the circle data.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The path to the CSV file containing the data. Defaults to CIRCLE_INPUT_FILE.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A pandas DataFrame with columns 'x' and 'y' representing the circle data.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filepath_or_buffer=path, header=None).set_axis(labels=['x', 'y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **plotting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the data (since we are dealing with 2D points) to understand the spacial placement of the points and to discuss the most suited cluster algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPoint(points: pd.DataFrame, title: str = 'Points') -> None:\n",
    "    \"\"\"\n",
    "    Plots 2D points from a DataFrame, optionally coloring them by cluster.\n",
    "\n",
    "    Parameters:\n",
    "    points (pd.DataFrame): A DataFrame containing the points to plot. \n",
    "                           It must have columns 'x' and 'y'. \n",
    "                           If a 'cluster' column is present, points will be colored by cluster.\n",
    "    title (str, optional): The title of the plot. Defaults to 'Points' if not provided.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    \n",
    "    if 'cluster' in points.columns:\n",
    "        s = plt.scatter(points['x'], points['y'], c=points['cluster'], cmap='viridis')\n",
    "        fig.legend(*s.legend_elements(), title='Cluster')\n",
    "    else:\n",
    "        plt.scatter(points['x'], points['y'], color='blue', label='Points')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('x'),plt.ylabel('y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>1 - BUILDING $W$ SIMILARITY MATRIX </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of data points X and the similarity function:\n",
    "$ s_{i, j} = exp\\left( - \\frac{||X_i - X_j||^2}{2\\sigma^2}\\right)$\n",
    "\n",
    "construct the <em>k-nearest neighborhood</em> similarity graph and its adjacency\n",
    "matrix $W$ using $\\sigma = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSimilarityMatrix(points_2d_plane: pd.DataFrame, k: int = NEIGHBORS, sigma: int = 1)->np:\n",
    "    \"\"\"\n",
    "    Constructs a k-nearest neighborhood similarity graph and its adjacency matrix W.\n",
    "\n",
    "    Parameters:\n",
    "    circle (pd.DataFrame): A DataFrame containing the data points. It should have columns representing the coordinates of the points.\n",
    "    k (int): The number of nearest neighbors to consider for each point. Defaults to the global constant NEIGHBORS.\n",
    "    sigma (int): The parameter for the RBF kernel, controlling the width of the Gaussian. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A symmetric matrix representing the similarity graph, where each element (i, j) indicates the similarity between points i and j.\n",
    "    \"\"\"\n",
    "    \n",
    "    matrix = rbf_kernel(points_2d_plane, gamma=1.0/(2.0*sigma**2))\n",
    "    np.fill_diagonal(matrix, 0)\n",
    "\n",
    "    mask = np.zeros(matrix.shape, dtype=bool)\n",
    "    mask[np.arange(matrix.shape[0])[:, None], np.argpartition(-matrix, k, axis=1)[:, :k]] = True\n",
    "\n",
    "    matrix = np.where(mask, matrix, 0)\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            if matrix[i, j] > EPS:\n",
    "                matrix[j, i] = matrix[i, j]\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Symmetry problem</b></h4>\n",
    "The main problem that may occur when building this matrix is related to the required symmetry. \n",
    "\n",
    "Moreover, the given matrix $W$ must be symmetric since we are dealing with a weighted, non-oriented graph. <br>\n",
    "However, this may not always be the case because, even if weights are computed symmetrically (i.e., $\\forall i,j, s_{i,j} = s_{j,i}$), considering the $k-nearest \\text{ }neighbors$ may create asymmetry:  \n",
    "If a vertex $V$ is a neighbor of $V'$, we cannot be sure of the opposite, as shown here, 2 of the k-nearest neighbor of the green point are the red ones. But it may be not the same with respect to the red ones.<br>\n",
    "<img src='./pictures/output.png' alt='KNN problem'></img>\n",
    "<br>\n",
    "To address this issue, we can use one of two approaches (relaxing the constraint of having exactly $k$ neighbors):\n",
    "<ul>\n",
    "    <li>Impose that if <em>V</em> is a neighbor of <em>V'</em>, then <em>V'</em> is also a neighbor of <em>V</em>, thus potentially allowing more than <em>k</em> neighbors for a single vertex.</li>\n",
    "    <li>Impose that if <em>V</em> is not a neighbor of <em>V'</em>, then <em>V'</em> is also not a neighbor of <em>V</em>, thus potentially allowing fewer than <em>k</em> neighbors for a single vertex.</li>\n",
    "</ul>\n",
    "We have chosen the first approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>2 - BUILD DEGREE MATRIX $D$ AND LAPLACIAN MATRIX $L$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the degree diagonal matrix $D$ where each diagonal entry is obtained by summing the respective row of the similarity matrix $W$.<br>\n",
    "$$D_{i,i} = \\sum_{j=1}^N W_{i,j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDegreeMatrix(matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Constructs the degree matrix for a given adjacency matrix.\n",
    "\n",
    "    Parameters:\n",
    "    matrix (np.ndarray): A 2D numpy array representing the adjacency matrix of a graph.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A diagonal matrix where each diagonal element represents the degree of the corresponding vertex.\n",
    "    \"\"\"\n",
    "    return np.diag(matrix.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the <b>Laplacian matrix</b> $L = D − W$.<br>\n",
    "Note: we can also build the <b>normalized symmetric Laplacian matrix</b>\n",
    "$L_{sym} \\in R^{N,N}$ that is defined as $ L_{sym} := D ^{− \\frac{1}{2}} LD^{−\\frac{1}{2}} = I − D^{-\\frac{1}{2}}WD^{-\\frac{1}{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLaplacianMatrix(D: np.ndarray, W: np.ndarray, computeNormalizedLaplacian: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Constructs the Laplacian matrix for a given graph.\n",
    "\n",
    "    Parameters:\n",
    "    D (np.ndarray): The degree matrix of the graph, which is a diagonal matrix where each diagonal element \n",
    "                    represents the degree of the corresponding vertex.\n",
    "    W (np.ndarray): The adjacency matrix of the graph, representing the similarity between nodes.\n",
    "    computeNormalizedLaplacian (bool): A flag indicating whether to compute the normalized Laplacian matrix. \n",
    "                                        Defaults to False, which computes the unnormalized Laplacian.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The Laplacian matrix of the graph. If computeNormalizedLaplacian is False, it returns the \n",
    "                unnormalized Laplacian (D - W). If True, it returns the normalized Laplacian.\n",
    "    \"\"\"\n",
    "    if not computeNormalizedLaplacian:\n",
    "        return D[np.diag_indices(n=D.shape[0])], W, D - W\n",
    "\n",
    "    D_sqrt = D.copy()\n",
    "    D_sqrt[np.diag_indices(n=D.shape[0])] **= -1 / 2\n",
    "\n",
    "    return D_sqrt[np.diag_indices(D.shape[0])], W, np.eye(N=D.shape[0]) - D_sqrt @ W @ D_sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>setAsSparseMatrix</b>\n",
    "Given a matrix as input, returns the same matrix in a sparse format. <br>\n",
    "We have chosen to use an approach similar to the <b>modified CSR sparse format</b> to prioritize the diagonal of the matrix. <br>\n",
    "Which is particularly convenient when dealing with matrices such as the degree matrix $D$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAsSparseMatrix(matrix: np.ndarray, method: sparse.dia_array | None = sparse.dia_array) -> sparse:\n",
    "    \"\"\"\n",
    "    Converts a given matrix into a sparse format using the specified method.\n",
    "\n",
    "    Parameters:\n",
    "    matrix (np.ndarray): The matrix to be converted into a sparse format.\n",
    "    method (sparse.dia_array or None): The sparse format method to use for conversion. \n",
    "                                       Defaults to sparse.dia_array if not specified.\n",
    "\n",
    "    Returns:\n",
    "    sparse: The matrix converted into the specified sparse format.\n",
    "    \"\"\"\n",
    "    return method(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the Laplacian matrix is built using the previously declared function. <br>\n",
    "Moreover, since we will only be working with $L$ from now on, we can convert $D$ and $W$ into a sparse matrix format. <br>\n",
    "We prefer not to convert $L$ since it will still be used for many different purposes. <br>\n",
    "Due to the structure of $W$ we opted to convert it into a modified CSR format, whilst we only store the diagonal of D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = readSpiralInput(SPIRAL_INPUT_FILE) if USE_SPIRAL else readCircleInput(CIRCLE_INPUT_FILE)\n",
    "plotPoint(data, title='points of ' + 'spiral.csv' if USE_SPIRAL else 'Circle.csv')\n",
    "\n",
    "W = buildSimilarityMatrix(data[['x', 'y']])\n",
    "D = buildDegreeMatrix(W)\n",
    "\n",
    "D, W, L = buildLaplacianMatrix(D, W, computeNormalizedLaplacian=False)\n",
    "\n",
    "W = setAsSparseMatrix(W, method=sparse.csr_matrix)\n",
    "\n",
    "# We can also check if we have compute correctly the normalized laplacian\n",
    "print(f'{\"NOT\" if any(np.unique(L[np.diag_indices(L.shape[0])]) != 1) else \"\"} Normalized Laplacian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>3 - CONNECTED COMPONENT OF THE GRAPHS </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of connected components of the similarity graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLaplacian(L: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Plots the sparsity pattern of the Laplacian matrix.\n",
    "\n",
    "    Parameters:\n",
    "    L (np.ndarray): The Laplacian matrix to be visualized. It is expected to be a 2D numpy array.\n",
    "\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plt.spy(L)\n",
    "    ax.set_title(f'Laplacian matrix for {NEIGHBORS} neighbors')\n",
    "    plt.show()\n",
    "    \n",
    "plotLaplacian(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost, as expected, the Laplacian matrix $L$ is symmetric. <br>\n",
    "Moreover, it is a sparse matrix, with most of the non-zero elements located near the main diagonal. <br>\n",
    "Finally, and most importantly, we can conclude that the graph is primarily composed of three main components (represented by the three blocks along the diagonal), which are weakly connected, as indicated by the small black patches far from the main diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>4/5 - EIGENVALUES AND EIGENVECTORS OF $L$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute some of the small eigenvalues of $L$ and use their values to choose a suitable number of clusters $M$ for the data points. <br>\n",
    "From what we have previously observed, we can conclude that the graph has $3$ main components. <br>\n",
    "However, we are going to compute the first $10$ eigenvalues, mainly because the graph also shows $6$ more patches with non-zero values (even though the patches are symmetric), indicating a weak connection between the $3$ main components of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>USING SCIPY IMPLEMENTATION</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily compute eigenvalues using the eigh function within scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printEigenValues(eigVal: np.ndarray, legendText: str) -> None:\n",
    "    \"\"\"\n",
    "    Plots and displays the eigenvalues of a matrix.\n",
    "\n",
    "    Parameters:\n",
    "    eigVal (np.ndarray): An array of eigenvalues to be plotted and displayed.\n",
    "    legendText (str): A string to be used as the legend label for the plot.\n",
    "\n",
    "    \"\"\"\n",
    "    n = eigVal.shape[0]\n",
    "    print(f\"Computed the following {n} eigenvalues\")\n",
    "    for i, item in enumerate(eigVal):\n",
    "        display(Math(rf\"\\hspace{{2em}}\\lambda_{{{i+1}}} = {item}\"))\n",
    "\n",
    "    plt.subplots(1, 1, figsize=(8, 8))\n",
    "    plt.plot(values := range(1, n + 1), eigVal)\n",
    "    plt.scatter(values, eigVal, c='red', label=legendText)\n",
    "    plt.xticks(values)\n",
    "    plt.ylabel(\"Eigenvalue\"), plt.xlabel('#Eigenvalue')\n",
    "    plt.title(f\"First {n} Eigenvalues for {NEIGHBORS} neighbors\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(visible=True)\n",
    "    plt.show()\n",
    "    \n",
    "printEigenValues(eigh(L,subset_by_index=[0, 9],eigvals_only=True), \"eigenvalue's of scipy's method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>INVERSE POWER METHOD</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "To evaluate the eigenvalues we can also implement the <b>inverse power method</b> algorithm. \n",
    "<h4><b>Theoretical aspects</b></h4>\n",
    "\n",
    "Let $A \\in R^{n,n}$, we can define $\\lambda_n$ as the eigenvalue of A with smallest magnitude (i.e. $|\\lambda_n| \\leq |\\lambda_i|, \\forall i \\in [1,n]$). <br>\n",
    "Moreover, assuming A is invertible (and this is our case) we have that the eigenvalues of the inverse of A are the inverse of the eigenvalues of the matrix A <br>(i.e. $\\forall i \\in [1, n], Ax_i = \\lambda_i x_i \\implies A^{-1}x_i = \\frac{1}{\\lambda_i}x_i$ if A is invertible ).<br>\n",
    "Thus implying that if $|\\lambda_n| \\leq |\\lambda_i|, \\forall i \\in [1,n]$ then $\\frac{1}{|\\lambda_n|} \\geq \\frac{1}{|\\lambda_i|}, \\forall i \\in [1,n]$ <br>\n",
    "Finally, we can compute the eigenvalues by using the power method applied to the inverse of A, i.e. $A^{-1}$.\n",
    "<br>\n",
    "<h4><b>Algorithm</b></h4>\n",
    "This is the algorithm that we are going to implement:\n",
    "<ul>\n",
    "<li><b>Inputs</b>: \n",
    "\n",
    "$A$ (matrix), $V$ (initial guess vector), $p$ (initial guess for eigenvalue), $maxIter$ (maximum iterations), $tol$ (tolerance)\n",
    "\n",
    "</li>\n",
    "<li><b>Algorithm</b>:</li>\n",
    "<ol>\n",
    "    <li>\n",
    "\n",
    "Normalize the initial guess vector $ V_0 \\leftarrow \\frac{V_0}{\\|V_0\\|_2} $\n",
    "</li>\n",
    "<li>\n",
    "\n",
    "Set $ \\mu_0 = 0 $ and initialize $ k = 0 $.</li>\n",
    "    <li>Repeat until convergence (i.e. $|\\mu_k -\\mu_{k-1}| \\leq tol\\cdot|\\mu_k| $) or $ k \\geq \\text{maxIter} $:\n",
    "        <ol type='I'>\n",
    "            <li>Compute $ V_{k+1} $ by solving $ (A - pI)V_k = V_{k+1} $.</li>\n",
    "            <li>Update $ \\mu_{k-1} = \\mu_k$ and $\\mu_k = V_{k+1} * V_{k} $.</li>\n",
    "            <li>Normalize $ V_{k+1} \\leftarrow \\frac{V_{k+1}}{\\|V_{k+1}\\|_2} $.</li>\n",
    "            <li>Update $k \\leftarrow k+1$</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ol>\n",
    "<li><b>Outputs</b>: \n",
    "\n",
    "The eigenvalue $ \\lambda_j = p + \\frac{1}{\\mu_k} $ and the eigenvector $ V_k $.\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "The main issue is the fact that if we apply the inverse power method to the $L$ matrix $10$ times we are going to get the same eigenpair $10$ times.<br>\n",
    "Once computed the eigenpair, we have to move it out of the way so that we may compute the remaining eigenpairs.<br>\n",
    "To do so, we can use either one of two techniques: <b>Shifting</b> or <b>Deflation</b>.\n",
    "\n",
    "<h4><b>Shifting</b></h4>\n",
    "\n",
    "This technique can only be applied to symmetric matrix (and, luckily for us, $L$ is symmetric), this requirement is imposed so that we may deal with real eigenvalues and orthogonal eigenvectors <br>\n",
    "i.e. let $A \\in R^{n,n} \\text{ symmetric } \\implies \\forall i \\in [1, n], \\lambda_i \\in \\mathbb{R}$ and $\\forall j \\in [1, n], x_i * x_j = \\delta_{ij}$<br>\n",
    "We assume knowing the eigenpair $\\lambda_1, x_1$, given that eigenpair we can compute $A' = A - \\lambda_1\\cdot x_1 x_1^T \\in R^{n,n}$ with $x_1x_1^T \\in R^{n,n}$ and of rank 1. <br>\n",
    "The new matrix $A'$ has the same eigenvectors of $A$ and almost the same eigenvalues, except for the first one. <br>\n",
    "i.e. defining with $\\lambda_i$ the eigenvalues of $A$ and $\\lambda_i'$ the eigenvalues of $A'$ then $\\forall i \\in [2, n], \\lambda_i = \\lambda_i'$ and for $i=1 \\lambda_i' = 0$<br>\n",
    "Which implies that we have effectively created a new matrix that has the vector $\\lambda_1x_1$ into it's right kernel, thus removing it from it's eigenvalues and adding $0$ as eigenvalue.<br>\n",
    "\n",
    "When dealing with the <b>power method</b> this is sufficient, since we are always evaluating the eigenvalue with the highest magnitude (and $0$ is the lowest possible magnitude).<br>\n",
    "However when dealing with the <b>inverse power method</b> this may prove counter productive since $\\frac{1}{0+\\epsilon}$ (with $\\epsilon$ due to machine precision) is going to skyrocket, thus getting in the way when calculating eigenvalues with this method. <br>\n",
    "Instead we have to create $A'$ in such a way that the eigenvalue $\\lambda_1$ gets a really high magnitude, such that, $\\frac{1}{\\lambda_1}$ becomes so low that is no longer a problem with this method. <br>\n",
    "The best way to do so, in our case, is the following $A' = A + \\alpha\\lambda_1\\cdot x_1 x_1^T$ with $ \\alpha \\approx 10^{15}$ \n",
    "\n",
    "<h4><b>Deflation</b></h4>\n",
    "\n",
    "Let $A \\in R^{n,n}$ and let $(\\lambda_1, x_1)$ be an eigenpair of $A$ and let $P_1 \\in R^{n,n}$ orthogonal such that: <br>\n",
    "$B_1 = P_1 A P_1^T = \\begin{bmatrix} \\lambda_1 --- b_1 --- \\\\ 0 \\hspace{7em} \\\\ | \\hspace{1em} A_2  \\in R^{n-1, n-1}\\\\ 0 \\hspace{7em} \\end{bmatrix} \\in R^{n,n}$.<br>\n",
    "The eigenvalues of $A_2$ will almost be the same of the ones of $A$, in fact, defining as $\\lambda$ the eigenvalues of $A$ and as $\\lambda'$ the eigenvalues of $A_2$, then, $\\forall i \\in [2, n], \\lambda_i = \\lambda_{i-1}' \\implies \\{\\lambda'\\} \\cup \\{\\lambda_1\\} = \\{\\lambda\\}$. <br>\n",
    "We have to notice that the first column of $B_1 = B_1*e_1^n = \\lambda_1 \\cdot e_1^n $. <br>\n",
    "We can define $P_1 = I_n - 2 \\frac{(x_1+e^n_1)(x_1+e^n_1)^T}{|| x_1 + e^n_1||_2^2}$. <br>\n",
    "Moreover, we can see how once we have computed the eigenpair $(\\lambda_2, x_2)$ we can use again this procedure to deflate $A_2$ being careful with using vector of size $n-1$ (i.e. $e^{n-1}_1$). <br>\n",
    "Moreover, with this method, the computed eigenvalues won't vary, but eigenvectors will! <br>\n",
    "This is, in fact, the main downside of using this method.<br>\n",
    "Whilst the first three eigenvectors can be easily compute by solving the following:\n",
    "<ul>\n",
    "<li>\n",
    "\n",
    "$x_1 = x_1'$\n",
    "</li>\n",
    "<li>\n",
    "\n",
    "$x_2 = P_1 * \n",
    "\\begin{bmatrix}\n",
    "     &  \\alpha\\\\\n",
    "     & \\vdots \\\\\n",
    "     & x_2' \\in R^{n-1} \\\\\n",
    "     & \\vdots\n",
    "\\end{bmatrix} \\quad\\quad \\text{with : } \\alpha = - \\frac{b_1^T * x_2'}{\\lambda_1 - \\lambda_2}$\n",
    "\n",
    "</li>\n",
    "<li>\n",
    "\n",
    "$ x_3 = P_1*P_2 * \\begin{bmatrix}\n",
    "     &  \\alpha\\\\\n",
    "     & \\beta \\\\\n",
    "     & \\vdots \\\\\n",
    "     & x_3' \\in R^{n-2} \\\\\n",
    "     & \\vdots\n",
    "\\end{bmatrix} \\quad\\quad \\text{with : }\n",
    "\\begin{cases}\n",
    "(\\lambda_1 - \\lambda_3)\\alpha = -b_1^T P_2' * \\begin{bmatrix}\n",
    "     &  \\beta\\\\\n",
    "     & \\vdots \\\\\n",
    "     & x_3' \\in R^{n-2} \\\\\n",
    "     & \\vdots\n",
    "\\end{bmatrix} \\\\\n",
    "(\\lambda_2 - \\lambda_3)\\beta = -b_2^T x_3' \n",
    "\\end{cases}$\n",
    "\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "from the fourth one onward it may not be so easy to do so, <br>\n",
    "thus to compute them we can solve the following linear system since we do know the respective eigenvalue:<br>\n",
    "\n",
    "$$Ax_i = \\lambda_i x_i \\implies Ax_i - \\lambda_i x_i = 0_{n} \\implies (A-\\lambda_i * I_{n,n})x_i = 0_n$$\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "Now we can apply the <b>Inverse power method with either deflation or shifting</b> (both solution are proposed) to $L$ to compute the first ten eigenvalues and the corresponding eigenvectors.<br>\n",
    "The shape of $L$ is already pretty good, we don't have to modify it to make the algorithm more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Inverse power method</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inversePowerMethodAlgorithm(A: np.ndarray, V: np.ndarray, p: float, maxIter: int = 1e4, tol: float = 1e-5) -> list[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Implements the Inverse Power Method algorithm to find the eigenvalue and eigenvector of a matrix.\n",
    "\n",
    "    This function uses the inverse power method to find the eigenvalue closest to a given shift 'p' (initial guess of the eigenvalue).\n",
    "    and its corresponding eigenvector for the input matrix A.\n",
    "\n",
    "    Parameters:\n",
    "    A (np.ndarray): The input matrix for which to find the eigenvalue and eigenvector.\n",
    "    V (np.ndarray): Initial guess for the eigenvector.\n",
    "    p (float): The shift value used in the inverse power method, initial guess of the eigenvalue.\n",
    "    maxIter (int, optional): Maximum number of iterations. Defaults to 1000.\n",
    "    tol (float, optional): Tolerance for convergence. Defaults to EPS.\n",
    "\n",
    "    Returns:\n",
    "    list: A list containing two elements:\n",
    "        - float: The computed eigenvalue.\n",
    "        - np.ndarray: The computed eigenvector.\n",
    "    \"\"\"\n",
    "    V = V/np.linalg.norm(V,2)\n",
    "    pI = p*np.eye(A.shape[0])         # Precomputed to have a faster execution\n",
    "    mu_prev, mu, k = 0, 1, 0\n",
    "        \n",
    "    M = A - pI\n",
    "    while k < maxIter and np.abs(mu - mu_prev)>=tol*np.abs(mu):\n",
    "        Vk = np.linalg.solve(M, V)\n",
    "        mu, mu_prev = np.dot(Vk,V), mu\n",
    "        V = Vk/np.linalg.norm(Vk, 2)\n",
    "        k += 1\n",
    "        \n",
    "    return p + 1/mu, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Using Shifting </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyInversePowerMethodWithShifting(A: np, numEig: int = EIGENPAIRS, maxIter: int = 1e4, tol: float = 1e-5) -> list[list[float], list[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    This function implements the Inverse Power Method with shifting to compute the specified\n",
    "    number of eigenvalues and eigenvectors of the input matrix A.\n",
    "\n",
    "    Parameters:\n",
    "    A (np.ndarray): The input matrix for which to find eigenvalues and eigenvectors.\n",
    "    numEig (int): The number of eigenvalues and eigenvectors to compute. Defaults to EIGENPAIRS.\n",
    "    maxIter (int): The maximum number of iterations for the inverse power method. Defaults to 1e4.\n",
    "    tol (float): The tolerance for convergence in the inverse power method. Defaults to EPS.\n",
    "\n",
    "    Returns:\n",
    "    list: A list containing two elements:\n",
    "        - list[float]: The computed eigenvalues.\n",
    "        - list[np.ndarray]: The computed eigenvectors.\n",
    "    \"\"\"\n",
    "    temp = A.copy()\n",
    "    \n",
    "    # Pre allocated for speed \n",
    "    eigVal, eigVecs = np.zeros(numEig), np.zeros((A.shape[0], numEig))\n",
    "    \n",
    "    i = 0\n",
    "    while i < numEig:\n",
    "        eigVal[i], eigVecs[:, i] = inversePowerMethodAlgorithm(temp, np.random.rand(A.shape[0]), p=1e-16, maxIter=maxIter, tol=tol)\n",
    "\n",
    "        vect = eigVecs[:, i].reshape(-1, 1)\n",
    "        temp += 1e8*eigVal[i] * (vect @ vect.T)  \n",
    "        \n",
    "        if np.abs(eigVal[i]) < 1e-14 or np.abs(eigVal[i]) >1e-6:\n",
    "            i+=1\n",
    "        \n",
    "    return eigVal, eigVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Using Deflation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyInversePowerMethodWithDeflation(A:np.ndarray, numEig:int=EIGENPAIRS, maxIter:int=1e4, tol: float=EPS) -> list[list[float], list[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    This function implements the Inverse Power Method with deflation to compute the specified\n",
    "    number of eigenvalues and eigenvectors of the input matrix A.\n",
    "\n",
    "    Parameters:\n",
    "    A (np.ndarray): The input matrix for which to find eigenvalues and eigenvectors.\n",
    "    numEig (int): The number of eigenvalues and eigenvectors to compute. Defaults to EIGENPAIRS.\n",
    "    maxIter (int): The maximum number of iterations for the inverse power method. Defaults to 1e4.\n",
    "    tol (float): The tolerance for convergence in the inverse power method. Defaults to EPS.\n",
    "\n",
    "    Returns:\n",
    "    list: A list containing two elements:\n",
    "        - list[float]: The computed eigenvalues.\n",
    "        - list[np.ndarray]: The computed eigenvectors.\n",
    "    \"\"\"\n",
    "    # Pre allocated for speed \n",
    "    eigVal, eigVecs, matrix = np.zeros(numEig), np.zeros((A.shape[0], numEig)), A.copy()\n",
    "\n",
    "    # creates the tensor for storing P, moreover, we are just going to store the first 2 P matrices and a third one which is the current working one, \n",
    "    # we won't need the others as eigenvalues are computed without need of storing P, and from the fourth eigenvector onward we \n",
    "    # will use a different method to compute it that does not rely on P\n",
    "    P = np.array([np.eye(matrix.shape[0])]*3)   # [#tensor, row, col]\n",
    "\n",
    "    for i in range(0, min(P.shape[0], numEig)):\n",
    "        matrix = P[i-1] @ matrix @ P[i-1].T\n",
    "\n",
    "        eigVal[i], eigVecs[i:, i] = inversePowerMethodAlgorithm(\n",
    "            matrix[i:, i:], \n",
    "            np.random.rand(A.shape[0]-i), \n",
    "            p=1e-10, \n",
    "            maxIter=maxIter, \n",
    "            tol=tol\n",
    "        )  \n",
    "        \n",
    "        temp = eigVecs[i:, i].reshape(-1,1) + np.eye(N=A.shape[0]-i, M=1)\n",
    "\n",
    "        P[i, :, :] = np.eye(A.shape[0])\n",
    "        P[i, i:, i:] -= 2*(temp.T*temp)/np.linalg.norm(temp, 2)**2 \n",
    "\n",
    "\n",
    "        match i:\n",
    "            case 1:\n",
    "                eigVecs[0, 1]= -np.dot(eigVecs[1:, 1], matrix[0, 1:])/(eigVal[0]- eigVal[1]) if np.abs(eigVal[0] - eigVal[1]) > tol else 0\n",
    "                eigVecs[:, 1] = P[0, :, :]@eigVecs[:, 1]\n",
    "\n",
    "            case 2:\n",
    "                eigVecs[1, 2]= -np.dot(eigVecs[2:, 2], matrix[1, 2:])/(eigVal[1]- eigVal[2]) if np.abs(eigVal[1] - eigVal[2]) > tol else 0\n",
    "                eigVecs[0, 2]= -np.dot(matrix[0, 1:], np.dot(P[1, 1:, 1:], eigVecs[1:, 2]))/(eigVal[0]- eigVal[2]) if np.abs(eigVal[0] - eigVal[2]) > tol else 0\n",
    "                eigVecs[:, 2] = P[0, :, :]@(P[1, :, :]@eigVecs[:, 2])\n",
    "\n",
    "    for i in range(P.shape[0], numEig):\n",
    "        matrix = P[-1] @ matrix @ P[-1].T\n",
    "\n",
    "        eigVal[i], eigVecs[i:, i] = inversePowerMethodAlgorithm(\n",
    "                matrix[i:, i:], \n",
    "                np.random.rand(A.shape[0]-i), \n",
    "                p=1e-10, \n",
    "                maxIter=maxIter, \n",
    "                tol=tol\n",
    "        )\n",
    "\n",
    "        temp = eigVecs[i:, i].reshape(-1,1) + np.eye(N=A.shape[0]-i, M=1)\n",
    "\n",
    "        P[-1, :, :] = np.eye(A.shape[0])\n",
    "        P[-1, i:, i:] -= 2*(temp.T*temp)/np.linalg.norm(temp, 2)**2 \n",
    "\n",
    "        eigVecs[:, i] = null_space(A-eigVal[i]*np.eye(A.shape[0]))[:,0]\n",
    "\n",
    "    return eigVal, eigVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>VISUALIZING AND COMPARING RESULTS</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can compare the results between the two different implementations, with library values as a reference:\n",
    "<ul>\n",
    "<li><b>Shifting</b>: implementation of the <b>Inverse power method</b> using shifting.</li>\n",
    "<li><b>Deflation</b>: implementation of the <b>Inverse power method</b> using deflation.</li>\n",
    "<li><b>Scipy</b>: calculating the eigenpairs via the eigh function within the scipy module.</li>\n",
    "</ul>\n",
    "<b>NOTE:</b> we will only compare eigenvalues and not eigenvectors due to the high dimensionality of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparisonBetweenEigenvaluesMethod(df: pd.DataFrame, plotSingle: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Compare and visualize eigenvalues calculated using different methods.\n",
    "\n",
    "    This function creates plots to compare eigenvalues computed using different methods\n",
    "    (shifting, deflation, and scipy). It generates a combined plot of all methods and\n",
    "    optionally individual plots for each method.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): A DataFrame containing eigenvalues computed by different methods.\n",
    "                       Each column should represent a method (shifting, deflation, scipy),\n",
    "                       and each row should represent an eigenvalue.\n",
    "    plotSingle (bool): If True, create individual plots for each method in addition to\n",
    "                       the combined plot. Defaults to False.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Eigenvalues calculated : {df.shape[0]}\")\n",
    "    display(df)\n",
    "    param = {   'shifting':{'c':'red', 'marker':'*'}, \n",
    "                'deflation':{'c':'blue', 'marker':'x'}, \n",
    "                'scipy':{'c':'green', 'marker':'^'}}\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(16,8))    \n",
    "    for col in df.columns[::-1]:\n",
    "        ax.plot(df.index, df[col])\n",
    "        ax.scatter(df.index, df[col], label=col, **param[col])\n",
    "        \n",
    "\n",
    "    plt.xticks(range(df.index.shape[0]), rotation=-60)\n",
    "    plt.ylabel(\"Eigenvalue\")\n",
    "    plt.title(\"Direct comparison between eigenvalues methods\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(visible=True)\n",
    "    plt.show()\n",
    "    if plotSingle:\n",
    "        fig, ax = plt.subplots(3,1,figsize=(8, 24))\n",
    "        for i,col in enumerate(df):\n",
    "            ax[i].plot(df.index, df[col])\n",
    "            ax[i].scatter(df.index, df[col], label=col, **param[col])\n",
    "            \n",
    "            ax[i].set_xticks(range(1, df.index.shape[0]+1))\n",
    "            ax[i].set_xticklabels(df.index, rotation=-80)\n",
    "            ax[i].set_ylabel(\"Eigenvalue\")\n",
    "            ax[i].set_title(f\"First {df.shape[0]} Eigenvalues with method {col}\")\n",
    "            ax[i].legend(loc='upper left')\n",
    "            ax[i].grid(visible=True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "if ENABLE_COMPARISON:\n",
    "    (lambda eigs: comparisonBetweenEigenvaluesMethod(pd.DataFrame(\n",
    "                                    zip(applyInversePowerMethodWithShifting(L, numEig=eigs, tol=1e-7)[0], \n",
    "                                        applyInversePowerMethodWithDeflation(L, numEig=eigs)[0], \n",
    "                                        eigh(L,subset_by_index=[0, eigs-1],eigvals_only=True)),\n",
    "    columns=['shifting', 'deflation', 'scipy'], index=[f'\\u03BB{i+1}' for i in range(EIGENPAIRS)], dtype=np.float32)))(EIGENPAIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if the eigenvectors match, if so then for each component of the same eigenvector if we divide it by the corresponding component of the benchmark implementation (scipy), then the rates will be constant, moreover, ideally they are going to be 1 or -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_COMPARISON:\n",
    "    display(pd.DataFrame(   {'deflation':{ i+1:{np.round(w1/w2) for w1, w2 in zip(v1, v2) if w2} for i, (v1, v2) in enumerate(zip(applyInversePowerMethodWithDeflation(L)[1].T, eigh(L, subset_by_index=[0,9])[1].T))}, \n",
    "            'shifting':{ i+1:{np.round(w1/w2) for w1, w2 in zip(v1, v2) if w2} for i, (v1, v2) in enumerate(zip(applyInversePowerMethodWithShifting(L)[1].T, eigh(L, subset_by_index=[0,9])[1].T)) }}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_COMPARISON:\n",
    "    from timeit import timeit\n",
    "    \n",
    "    (lambda runs, eigs, maxIter: \n",
    "    print(  f'Time of eigh {round(timeit(lambda:eigh(L, subset_by_index=[0,eigs-1]), number=runs)/runs, 5)}',\n",
    "            f'Time of inverse power method with deflation  {round(timeit(lambda:applyInversePowerMethodWithDeflation(L, numEig=eigs, maxIter=maxIter), number=runs)/runs, 5)}',\n",
    "            f'Time of inverse power method with shifting  {round(timeit(lambda:applyInversePowerMethodWithShifting(L, numEig=eigs, maxIter=maxIter), number=runs)/runs, 5)}', sep='\\n')\n",
    "    )(2, 10, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can compute the eigenpairs of $L$ with a method of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEigenpairs(L: np.ndarray, numEig: int = EIGENPAIRS, method: str | None = 'scipy', maxIter: int | None = 1e4, tol: float = EPS) -> list[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    This function calculates the eigenpairs of the input matrix L using one of three methods:\n",
    "    deflation, shifting, or scipy's eigh function.\n",
    "\n",
    "    Parameters:\n",
    "    L (np.ndarray): The input matrix for which to compute eigenpairs.\n",
    "    numEig (int): The number of eigenpairs to compute. Defaults to EIGENPAIRS.\n",
    "    method (str | None): The method to use for computation. Options are 'DEFLATION', 'SHIFTING', or 'scipy' (default).\n",
    "    maxIter (int | None): Maximum number of iterations for iterative methods. Defaults to 1e4.\n",
    "    tol (float): Tolerance for convergence in iterative methods. Defaults to EPS.\n",
    "\n",
    "    Returns:\n",
    "    list[np.ndarray, np.ndarray]: A list containing two numpy arrays:\n",
    "        - The first array contains the computed eigenvalues.\n",
    "        - The second array contains the corresponding eigenvectors.\n",
    "    \"\"\"\n",
    "    match method.strip().upper() if method and isinstance(method, str) else method:\n",
    "        case 'DEFLATION': return applyInversePowerMethodWithDeflation(A=L, numEig=numEig, maxIter=maxIter, tol=tol)\n",
    "        case 'SHIFTING': return applyInversePowerMethodWithShifting(A=L, numEig=numEig, maxIter=maxIter, tol=tol)\n",
    "        case _:  return (eigenpairs := eigh(L, subset_by_index=[0, numEig-1], eigvals_only=False))[0], eigenpairs[1]\n",
    "    \n",
    "eigenvalues, U = computeEigenpairs(L, method='*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from now on we won't be needing L so we can convert it to a sparse format to save memory space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = setAsSparseMatrix(L, method=sparse.csr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing solely the eigenvalues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printEigenValues(eigenvalues, legendText='eigenvalues calculated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(U, index=[f'x[{i}, j]' for i in range(1, U.shape[0]+1)], columns=[f'x{i+1}' for i in range(U.shape[1])], dtype=np.float32)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independently from the method chosen, as expected, the first $3$ eigenvalues are $0$ or are really close to $0$. <br>\n",
    "Then there is another group of $3$ eigenvalues with values closer to $0.005$ which indicates a fairly weak connection between the three main components. <br>\n",
    "Moreover there is, also, another group of $3$ eigenvalues, with values higher than the previous one.<br>\n",
    "Finally, we can see how, starting from the $10^{th}$ eigenvalue, they become bigger and bigger, thus indicating an even stronger connection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>6 - CLUSTERING $U$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $i = 1, ..., N$ let $y_i \\in R^M$ be the vector corresponding to the $i-th$ row of $U$.\n",
    "<br> Cluster the points $i = 1, ..., N \\text{  } y_i\\in R^M$ with the <em>k-means algorithm</em> into clusters $C_1, ..., C_M$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusteringAndCentroidsOfU(U: np.ndarray, centroids: np.ndarray, clusterLabels: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    This function visualizes the clustering results by plotting data points colored by their\n",
    "    cluster assignments and the centroids of each cluster. It automatically determines whether\n",
    "    to create a 2D or 3D plot based on the dimensionality of the input data.\n",
    "\n",
    "    Parameters:\n",
    "    U (np.ndarray): The data points to be plotted. Each row represents a point, and the number\n",
    "                    of columns (2 or 3) determines whether a 2D or 3D plot is created.\n",
    "    centroids (np.ndarray): The coordinates of the cluster centroids. Should have the same\n",
    "                            number of columns as U.\n",
    "    clusterLabels (np.ndarray): An array of cluster labels for each point in U.\n",
    "    \"\"\"\n",
    "    \n",
    "    if U.shape[1] == 3:  \n",
    "        ax = plt.figure(figsize=(10, 8)).add_subplot(111, projection='3d')\n",
    "        \n",
    "        for label, color in zip(np.unique(clusterLabels), plt.cm.tab10(np.linspace(0, 1, len(np.unique(clusterLabels))))):\n",
    "            ax.scatter((points:=U[clusterLabels == label])[:, 0], points[:, 1], points[:, 2], c=[color], s=50, label=f'Cluster C{label}')\n",
    "\n",
    "        ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], c='black', marker='*', s=200, label='Centroids')\n",
    "        ax.set_zlabel('Z')  \n",
    "    else:\n",
    "        fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "        for label, color in zip(np.unique(clusterLabels), plt.cm.tab10(np.linspace(0, 1, len(np.unique(clusterLabels))))):\n",
    "            ax.scatter((points:=U[clusterLabels == label])[:, 0], points[:, 1], c=[color], s=50, label=f'Cluster C{label}')\n",
    "\n",
    "        ax.scatter(centroids[:, 0], centroids[:, 1], c='black', marker='*', s=200, label='Centroids')\n",
    "\n",
    "    # Titles and labels\n",
    "    ax.set_title('3D Scatter Plot with Clustering and Centroids')\n",
    "    ax.set_xlabel('X'),ax.set_ylabel('Y')\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# Example Data and Usage\n",
    "bestNumberOfEig = 3\n",
    "\n",
    "km = KMeans(n_clusters=bestNumberOfEig, tol=EPS, random_state=23)\n",
    "clusterLabels = km.fit_predict(U[:, :bestNumberOfEig])\n",
    "\n",
    "plotClusteringAndCentroidsOfU(U[:, :bestNumberOfEig], centroids, clusterLabels) if 2<= (centroids:=km.cluster_centers_).shape[1]<=3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>7- ASSIGNING CLUSTER TO THE POINTS</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the original points in $X$ to the same clusters as their corresponding\n",
    "rows in $U$ and construct the clusters $A_1, ..., A_M$ with $A_i = \\{x_j : y_j \\in C_i\\}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['k-means']=clusterLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> 8 - PLOTTING CLUSTERS </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the clusters of points $X$ with different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusteringResults(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Plots the clustering results for each method in the input DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): A DataFrame containing the clustering results. Each column represents a clustering method,\n",
    "                       and each row represents a data point. The DataFrame should have columns 'x' and 'y' representing\n",
    "                       the coordinates of the data points.\n",
    "    \"\"\"\n",
    "    columns: np.ndarray = df.columns.difference(['x', 'y', 'cluster']).sort_values()\n",
    "\n",
    "    # Create subplots for each clustering method\n",
    "    fig, ax = plt.subplots(columns.shape[0], 1, figsize=(8, 8 * columns.shape[0]))\n",
    "    ax = ax if len(columns) >1 else [ax]\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        scalarMap = cm.ScalarMappable(norm=colors.Normalize(vmin=min(unique_labels:=np.unique(df[column])), vmax=max(unique_labels)), \n",
    "                                        cmap=plt.get_cmap('tab10', len(unique_labels)))\n",
    "\n",
    "        ax[i].scatter(df['x'],df['y'], c=[scalarMap.to_rgba(label) for label in df[column]],s=50)\n",
    "\n",
    "        for label in unique_labels:\n",
    "            ax[i].scatter([], [], color=scalarMap.to_rgba(label), label=f'Cluster {label}')\n",
    "\n",
    "        ax[i].set_title(f'Clustering Method: {column}')\n",
    "        ax[i].set_xlabel('X'), ax[i].set_ylabel('Y')\n",
    "        ax[i].legend(loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotClusteringResults(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(10, 20))\n",
    "axes = axes.ravel()  \n",
    "\n",
    "silhouette = np.zeros(shape=(maxCluster:=15)-2, dtype=np.float32)\n",
    "\n",
    "for i in range(2, maxCluster):  \n",
    "    km = KMeans(n_clusters=i, tol=EPS, random_state=23)\n",
    "    \n",
    "    if i < 4*2 +2:\n",
    "        for label, color in zip(unique_labels := np.unique(clusterLabels := km.fit_predict(U[:, :i])), \n",
    "                                plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))):\n",
    "            axes[i-2].scatter((points:=data[clusterLabels == label].values)[:, 0], points[:, 1], c=[color], s=50)\n",
    "        \n",
    "        axes[i-2].set_title(f'KMeans with {i} Clusters')\n",
    "        axes[i-2].set_xlabel('X'), axes[i-3].set_ylabel('Y')\n",
    "        \n",
    "    silhouette[i-2] = silhouette_score(U[:, :i], clusterLabels)\n",
    "\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2,silhouette.shape[0]+2), silhouette)\n",
    "plt.scatter(range(2, silhouette.shape[0]+2), silhouette, marker='*', color='red')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('silhouette score')\n",
    "plt.xticks(range(2,silhouette.shape[0]+2))\n",
    "plt.title(f'Silhouette score obtained for {NEIGHBORS} neighbors on ' + ('Spiral.csv' if USE_SPIRAL else 'Circle.csv'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are working with $spiral.csv$ we are also given the labels of the cluster, and as such we can see the accuracy of the prediction <br>\n",
    "we can compute that as $\\frac{1}{N} \\sum_{k=1}^{N} \\delta(\\text{label predicted }= \\text{true label})$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SPIRAL:\n",
    "    print(f' Final accuracy score = {accuracy_score(y_true=data[\"cluster\"], y_pred=list(map(lambda x: {1:2, 0:1, 2:3}[x], KMeans(n_clusters=3, tol=EPS, random_state=23).fit_predict(U[:, :3]))))*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>9 - CLUSTERING METHODS COMPARISON</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the clusters for the same set of points with other clustering methods and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusters(df: pd.DataFrame, labels:np.ndarray, title:str|None=None) -> None:\n",
    "    \"\"\"\n",
    "    Plots the clusters for the input DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): A DataFrame containing the coordinates of the data points.\n",
    "    labels (np.ndarray): An array containing the labels assigned to each data point.\n",
    "    title (str|None): The title of the plot. Defaults to None.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for label in np.unique(labels):\n",
    "        plt.scatter(df[labels == label]['x'],df[labels == label]['y'], label=f'Cluster {label}' if label != -1 else 'Noise',s=50)\n",
    "    \n",
    "    # Add legend and axis labels\n",
    "    plt.title(f'Clustered Points {title or \" \"}')\n",
    "    plt.xlabel('X'), plt.ylabel('Y')\n",
    "    plt.legend(loc='upper right', title='Clusters')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusters(data[['x', 'y']], KMeans(n_clusters=3, random_state=23).fit_predict(data[['x', 'y']]), 'Naive KMeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for spiral eps=1.2, min_samples=3\n",
    "# for circle eps=0.8 min_samples=3 with 3 clusters\n",
    "# for circle eps=0.85 min_samples=3 with 2 clusters\n",
    "plotClusters(data[['x', 'y']], DBSCAN(eps=1.2 if USE_SPIRAL else 0.85, min_samples=3).fit_predict(data[['x','y']]), 'DBSCAN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusters(data[['x', 'y']], BisectingKMeans(n_clusters=3).fit_predict(data[['x','y']]), title='Bisecting KMeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearest_neighbors\n",
    "plotClusters(data[['x', 'y']], \n",
    "             SpectralClustering(n_clusters=3, random_state=23, n_init=20, gamma=0.5, \n",
    "                                affinity='rbf', n_neighbors=NEIGHBORS, eigen_tol=1e-6, n_jobs=-1).fit_predict(data[['x','y']]), \n",
    "             title='Sklearn Spectral clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>USING 3D DATA</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the 3D dataset, it has the following components:\n",
    "<ol>\n",
    "<li><b>x</b>: the x axis coordinate</li>\n",
    "<li><b>y</b>: the y axis coordinate</li>\n",
    "<li><b>z</b>: the z axis coordinate</li>\n",
    "<li><b>cluster</b>: the true cluster value for the point</li>\n",
    "</ol>\n",
    "\n",
    "Moreover, it has $N = 3000$ points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=RINGS_3D_INPUT_FILE, header=0)\n",
    "\n",
    "ax = plt.figure(figsize=(10, 8)).add_subplot(111, projection='3d')\n",
    "\n",
    "for i, (labels, color) in enumerate(zip(['Inner ring', 'Outer Ring', 'Intersecting Ring'],  ['blue', 'orange', 'green'])):\n",
    "    ax.scatter((temp := df[df['cluster']==i].values)[:, 0], temp[:, 1], temp[:, 2], label=labels, alpha=0.7, c=color)\n",
    "\n",
    "ax.set_xlabel(\"x\"), ax.set_ylabel(\"y\"), ax.set_zlabel(\"z\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Concentric Rings with Intersecting Ring\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>BUILDING $W$, $D$ AND $L$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously done, we can build the similarity matrix $W$ using the same similarity function, <br>\n",
    "then we can build the degree matrix $D$ and finally the Laplacian matrix $L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(8,8))\n",
    "D, W, L=buildLaplacianMatrix(buildDegreeMatrix(W:=buildSimilarityMatrix(df, 50)), W, computeNormalizedLaplacian=False)\n",
    "plt.spy(L);\n",
    "plt.title('Laplacian matrix for 50 neighbors');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot, there are mainly $3$ connected components forming the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>PLOTTING EIGENVALUES</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the first $10$ eigenvalues of $L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigVal, U= computeEigenpairs(L, numEig=10)\n",
    "printEigenValues(eigVal, 'Eigenvalues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first $3$ eigenvalues are approximately $0$, as such we can think of using the first $3$ eigenvectors to compute the matrix U, moreover we can also try using $3$ cluster centers when it comes to cluster the data.<br>\n",
    "We can also try, mainly to comment on the results, to cluster the data using a number of cluster anywhere in the range $[3, 9]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>CLUSTERING </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we try creating a cluster of the results using a $3$ cluster centers using the <em>K-Means</em> algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centr = 3\n",
    "\n",
    "km = KMeans(n_clusters=centr, tol=EPS, random_state=23)\n",
    "clusterLabels = km.fit_predict(U[:, :centr])\n",
    "\n",
    "plotClusteringAndCentroidsOfU(U[:, :centr], centroids, clusterLabels) if 2<= (centroids:=km.cluster_centers_).shape[1]<=3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <B>PLOTTING THE RESULTS</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the obtained clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3DCluster(df:pd.DataFrame, clusterLabels:np.ndarray, algorithm:str)->None:\n",
    "    \"\"\"Plot the cluster results using 3D scatter plot. \n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the coordinates of the data points.\n",
    "        clusterLabels (np.ndarray): An array containing the labels assigned to each data point.\n",
    "        algorithm (str): The algorithm used for clustering.\n",
    "    \"\"\"\n",
    "    ax = plt.figure(figsize=(10, 8)).add_subplot(111, projection='3d')\n",
    "\n",
    "    for label, color in zip(np.unique((clusterLabels)), \n",
    "                            plt.cm.tab10(np.linspace(0, 1, len(np.unique(clusterLabels))))):        \n",
    "        ax.scatter((points:=df[clusterLabels == label].values)[:, 0], points[:, 1], points[:, 2], c=[color], s=50, label=f'Cluster C{label}')\n",
    "        \n",
    "    ax.set_title(f'Clustering using {algorithm}')\n",
    "    ax.set_xlabel('X'),ax.set_ylabel('Y'),ax.set_zlabel('Z')\n",
    "    ax.legend(loc='best');\n",
    "\n",
    "\n",
    "plot3DCluster(df, clusterLabels, 'KMeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering performs quite well, managing to effectively create the wanted clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>TRYING OTHER NUMBER OF CLUSTERS</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to cluster the points using a different number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(10, 20), subplot_kw={'projection': '3d'})\n",
    "axes = axes.ravel()  \n",
    "\n",
    "silhouette = np.zeros(shape=(maxCluster:=15)-3, dtype=np.float32)\n",
    "\n",
    "for i in range(3, maxCluster):  \n",
    "    km = KMeans(n_clusters=i, tol=EPS, random_state=23)\n",
    "    \n",
    "    if i < 4*2 +3:\n",
    "        for label, color in zip(unique_labels := np.unique(clusterLabels := km.fit_predict(U[:, :i])), \n",
    "                                plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))):\n",
    "            axes[i-3].scatter((points:=df[clusterLabels == label].values)[:, 0], points[:, 1], points[:, 2], c=[color], s=50)\n",
    "        \n",
    "        axes[i-3].set_title(f'KMeans with {i} Clusters')\n",
    "        axes[i-3].set_xlabel('X'), axes[i-3].set_ylabel('Y'), axes[i-3].set_zlabel('Z')\n",
    "        \n",
    "    silhouette[i-3] = silhouette_score(U[:, :i], clusterLabels)\n",
    "\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can evaluate the clustering via the use of the <b>silhouette score</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "ax.plot(range(3, maxCluster), silhouette)\n",
    "ax.scatter(range(3,maxCluster), silhouette, c='red', marker='*', label='scores')\n",
    "ax.set_title('Silhouette score obtained with KMeans')\n",
    "ax.set_xlabel('Number of clusters'), ax.set_ylabel('Silhouette score')\n",
    "ax.set_xticks(list(range(3,maxCluster)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected , the best silhouette score obtained is reached for $3$ clusters.<br>\n",
    "Note: this is also the best silhouette score obtainable in general, since it range in the interval $[-1, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the final accuracy of the model and the prediction given that we have the labels.<br>\n",
    "we can compute that as $\\frac{1}{N} \\sum_{k=1}^{N} \\delta(\\text{label predicted }= \\text{true label})$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Final accuracy score = {accuracy_score(y_true=df[\"cluster\"], y_pred=list(map(lambda x: {1:0, 0:1, 2:2}[x], KMeans(n_clusters=3, tol=EPS, random_state=23).fit_predict(U[:, :3]))))*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> COMPARISON WITH OTHER CLUSTERING METHODS</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will do a quick comparison with other clustering methods, moreover we use:\n",
    "<ul>\n",
    "<li>Our implementation of the spectral clustering with KMeans</li>\n",
    "<li>KMeans alone</li>\n",
    "<li>Bisecting KMeans</li>\n",
    "<li>DBSCAN</li>\n",
    "<li>Scikit-learn implementation of the spectral clustering</li>\n",
    "</ul>\n",
    "We will use a different number of clusters (when possible), and evaluate by means of the silhouette score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> FINE TUNED DBSCAN </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot3DCluster(df[['x','y','z']], DBSCAN(min_samples=8, eps=0.2, n_jobs=-1).fit_predict(df[['x', 'y', 'z']]), 'DBSCAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <B> FINE TUNED KMEANS </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot3DCluster(df[['x','y','z']], KMeans(n_clusters=3).fit_predict(df[['x','y','z']]), 'Naive KMeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <B> FINE TUNED BISECTING KMEANS </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot3DCluster(df[['x', 'y', 'z']], BisectingKMeans(n_clusters=3).fit_predict(df[['x','y','z']]), 'Bisecting KMeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <B> FINE TUNED SPECTRAL CLUSTERING </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot3DCluster(df[['x', 'y', 'z']], \n",
    "             SpectralClustering(n_clusters=3, random_state=23, n_init=30, gamma=0.5, \n",
    "                                affinity='rbf', n_neighbors=50, eigen_tol=1e-8, n_jobs=-1).fit_predict(df[['x','y','z']]), \n",
    "            'Sklearn Spectral clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <B> FINE TUNED KMEANS, BISECTING KMEANS, SPECTRAL CLUSTERING </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showDownOfMethods(U:np.ndarray, maxCluster:int=11)-> dict[str:np.ndarray]:  \n",
    "    \"\"\"Show the silhouette scores obtained by different clustering methods.\n",
    "    \n",
    "    Parameters:\n",
    "    U (np.ndarray): The coordinates of the data points.\n",
    "    maxCluster (int): The maximum number of clusters.\n",
    "    \n",
    "    Returns:\n",
    "    dict[str:np]: A dictionary containing the silhouette scores for each clustering method.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'KMeans':np.zeros(shape=(maxCluster-3), dtype=np.float32) - 1,\n",
    "        'BisectingKMeans':np.zeros(shape=(maxCluster-3), dtype=np.float32) - 1,\n",
    "        'SpectralClustering':np.zeros(shape=(maxCluster-3), dtype=np.float32) - 1\n",
    "    }\n",
    "        \n",
    "    for i in range(3, maxCluster):\n",
    "        for key in (clustering := {\n",
    "            'KMeans':KMeans(n_clusters=i, tol=EPS),\n",
    "            'BisectingKMeans':BisectingKMeans(n_clusters=i, tol=EPS),\n",
    "            'SpectralClustering':SpectralClustering(n_clusters=i,n_components=i,random_state=23, gamma=0.5,\n",
    "                                                    affinity='rbf', n_neighbors=50, eigen_tol=EPS, n_jobs=-1)\n",
    "                                        }):    \n",
    "            results[key][i-3] = silhouette_score(U[:, :i], clustering[key].fit_predict(U[:, :i])) \n",
    "            \n",
    "    return results\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "\n",
    "for (key, color, marker) in zip(\n",
    "        (stats := {'our Implementations':silhouette} | showDownOfMethods(U, maxCluster)),\n",
    "        ['red', 'green', 'blue', 'purple'], ['*', 'x', 'o', '^']):\n",
    "    ax.plot(range(3, maxCluster), stats[key], color=color)\n",
    "    ax.scatter(range(3,maxCluster), stats[key], c=color, marker=marker, label=key)\n",
    "    \n",
    "ax.legend()\n",
    "ax.set_xticks(list(range(3, maxCluster)))\n",
    "ax.set_xlabel('Number of clusters'), ax.set_ylabel('Silhouette score')\n",
    "ax.set_title('Silhouette score obtained');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
